{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-16T04:23:23.310864Z","iopub.execute_input":"2022-07-16T04:23:23.311394Z","iopub.status.idle":"2022-07-16T04:23:23.346327Z","shell.execute_reply.started":"2022-07-16T04:23:23.311272Z","shell.execute_reply":"2022-07-16T04:23:23.345554Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import keras \nprint(keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:23.348061Z","iopub.execute_input":"2022-07-16T04:23:23.348467Z","iopub.status.idle":"2022-07-16T04:23:30.249788Z","shell.execute_reply.started":"2022-07-16T04:23:23.348433Z","shell.execute_reply":"2022-07-16T04:23:30.248654Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#### STEP-1 Loading all necessary libraries \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os, cv2, random, time, shutil, csv\nimport tensorflow as tf\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm import tqdm\nnp.random.seed(42)\n%matplotlib inline \nimport json\nimport os\nimport cv2\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D, Lambda, Dropout, InputLayer, Input\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:30.251244Z","iopub.execute_input":"2022-07-16T04:23:30.252341Z","iopub.status.idle":"2022-07-16T04:23:31.310520Z","shell.execute_reply.started":"2022-07-16T04:23:30.252301Z","shell.execute_reply":"2022-07-16T04:23:31.309528Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Data Paths\ntrain_dir = '/kaggle/input/dog-breed-identification/train/'\ntest_dir = '/kaggle/input/dog-breed-identification/test/'\n#Count/Print train and test samples.","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:31.313204Z","iopub.execute_input":"2022-07-16T04:23:31.313598Z","iopub.status.idle":"2022-07-16T04:23:31.323206Z","shell.execute_reply.started":"2022-07-16T04:23:31.313560Z","shell.execute_reply":"2022-07-16T04:23:31.319741Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Read train labels.\nlabels_dataframe = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\n#Read sample_submission file to be modified by pridected labels.\nsample_df = pd.read_csv('/kaggle/input/dog-breed-identification/sample_submission.csv')\n#Incpect labels_dataframe.\nlabels_dataframe.head(5)\n# here sample df is the format of data to be submitted into kaggle \n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:31.324958Z","iopub.execute_input":"2022-07-16T04:23:31.325661Z","iopub.status.idle":"2022-07-16T04:23:31.817932Z","shell.execute_reply.started":"2022-07-16T04:23:31.325624Z","shell.execute_reply":"2022-07-16T04:23:31.816807Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"labels_dataframe.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:31.819305Z","iopub.execute_input":"2022-07-16T04:23:31.819768Z","iopub.status.idle":"2022-07-16T04:23:31.826558Z","shell.execute_reply.started":"2022-07-16T04:23:31.819728Z","shell.execute_reply":"2022-07-16T04:23:31.825605Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# little reminder of working with file and folder with os \nprint(f\"number of pic in test_dir {len(os.listdir(test_dir))}\")\nprint(f\"number of pic in train dir {len(os.listdir(train_dir))}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:31.827978Z","iopub.execute_input":"2022-07-16T04:23:31.828702Z","iopub.status.idle":"2022-07-16T04:23:32.422028Z","shell.execute_reply.started":"2022-07-16T04:23:31.828663Z","shell.execute_reply":"2022-07-16T04:23:32.421074Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"so here the size of labels_dataframe and the size of train directory is the same \nand in train directory every file have unique name and in labels_dataframe we can see the label of that picture and labels_dataframe and train directory both are in ordered manned ","metadata":{}},{"cell_type":"code","source":"# lets crate the  number of unique labels we have available in our dataset \ndog_breeds = sorted(list(set(labels_dataframe.breed)))\nn_classes = len(dog_breeds)\nprint(n_classes)\nprint(dog_breeds[:10])\n\n\n# here we have 120 dog breeeds to classify ","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.423485Z","iopub.execute_input":"2022-07-16T04:23:32.423840Z","iopub.status.idle":"2022-07-16T04:23:32.434783Z","shell.execute_reply.started":"2022-07-16T04:23:32.423803Z","shell.execute_reply":"2022-07-16T04:23:32.433393Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# so these dog breeds are string so we need to change them into some number for classification\n#Map each label string to an integer label.\nclass_to_num = dict(zip(dog_breeds, range(n_classes)))\nclass_to_num","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.436453Z","iopub.execute_input":"2022-07-16T04:23:32.437157Z","iopub.status.idle":"2022-07-16T04:23:32.450499Z","shell.execute_reply.started":"2022-07-16T04:23:32.437119Z","shell.execute_reply":"2022-07-16T04:23:32.449285Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"(train_dir+labels_dataframe.id+'.jpg')[0]\n# this is how we will access the files from our training data ","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.455726Z","iopub.execute_input":"2022-07-16T04:23:32.456034Z","iopub.status.idle":"2022-07-16T04:23:32.470280Z","shell.execute_reply.started":"2022-07-16T04:23:32.456010Z","shell.execute_reply":"2022-07-16T04:23:32.469462Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"cv2.imread((train_dir+labels_dataframe.id+'.jpg')[0]).shape\n# size of image ","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.472229Z","iopub.execute_input":"2022-07-16T04:23:32.472790Z","iopub.status.idle":"2022-07-16T04:23:32.512162Z","shell.execute_reply.started":"2022-07-16T04:23:32.472755Z","shell.execute_reply":"2022-07-16T04:23:32.511304Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.imread((train_dir+labels_dataframe.id+'.jpg')[0]))","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.513979Z","iopub.execute_input":"2022-07-16T04:23:32.514232Z","iopub.status.idle":"2022-07-16T04:23:32.770928Z","shell.execute_reply.started":"2022-07-16T04:23:32.514209Z","shell.execute_reply":"2022-07-16T04:23:32.768139Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"labels_dataframe['file_name'] = labels_dataframe['id'].apply(lambda x:train_dir+f\"{x}.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.771973Z","iopub.execute_input":"2022-07-16T04:23:32.772382Z","iopub.status.idle":"2022-07-16T04:23:32.783426Z","shell.execute_reply.started":"2022-07-16T04:23:32.772341Z","shell.execute_reply":"2022-07-16T04:23:32.782551Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"labels_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.784942Z","iopub.execute_input":"2022-07-16T04:23:32.785599Z","iopub.status.idle":"2022-07-16T04:23:32.799534Z","shell.execute_reply.started":"2022-07-16T04:23:32.785547Z","shell.execute_reply":"2022-07-16T04:23:32.798552Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# now we need to map our breed category according the class_to_num \nlabels_dataframe['breed'] = labels_dataframe.breed.map(class_to_num)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.801221Z","iopub.execute_input":"2022-07-16T04:23:32.802015Z","iopub.status.idle":"2022-07-16T04:23:32.816235Z","shell.execute_reply.started":"2022-07-16T04:23:32.801986Z","shell.execute_reply":"2022-07-16T04:23:32.815180Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"labels_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.818358Z","iopub.execute_input":"2022-07-16T04:23:32.818987Z","iopub.status.idle":"2022-07-16T04:23:32.831055Z","shell.execute_reply.started":"2022-07-16T04:23:32.818951Z","shell.execute_reply":"2022-07-16T04:23:32.830006Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"y = to_categorical(labels_dataframe.breed)\n# encoded our y variable to pass in our model","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.832624Z","iopub.execute_input":"2022-07-16T04:23:32.833156Z","iopub.status.idle":"2022-07-16T04:23:32.842223Z","shell.execute_reply.started":"2022-07-16T04:23:32.833115Z","shell.execute_reply":"2022-07-16T04:23:32.841318Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"#### Uptill now we have created our dataframe with file names and categories ","metadata":{}},{"cell_type":"markdown","source":"#### Lets Design model architecture for feature extraction\n","metadata":{}},{"cell_type":"code","source":"from keras.applications.resnet_v2 import ResNet50V2 , preprocess_input as resnet_preprocess\nfrom keras.applications.densenet import DenseNet121, preprocess_input as densenet_preprocess\nfrom keras.layers.merge import concatenate\n\ninput_shape = (331,331,3)\ninput_layer = Input(shape=input_shape)\n\n\n#first extractor inception_resnet\npreprocessor_resnet = Lambda(resnet_preprocess)(input_layer)\ninception_resnet = ResNet50V2(weights = 'imagenet',\n                                     include_top = False,input_shape = input_shape,pooling ='avg')(preprocessor_resnet)\n\npreprocessor_densenet = Lambda(densenet_preprocess)(input_layer)\ndensenet = DenseNet121(weights = 'imagenet',\n                                     include_top = False,input_shape = input_shape,pooling ='avg')(preprocessor_densenet)\n\n\nmerge = concatenate([inception_resnet,densenet])\nmodel = Model(inputs = input_layer, outputs = merge)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:32.845264Z","iopub.execute_input":"2022-07-16T04:23:32.845725Z","iopub.status.idle":"2022-07-16T04:23:41.906375Z","shell.execute_reply.started":"2022-07-16T04:23:32.845697Z","shell.execute_reply":"2022-07-16T04:23:41.905413Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:41.908470Z","iopub.execute_input":"2022-07-16T04:23:41.909164Z","iopub.status.idle":"2022-07-16T04:23:41.948235Z","shell.execute_reply.started":"2022-07-16T04:23:41.909125Z","shell.execute_reply":"2022-07-16T04:23:41.947209Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.save('feature_extractor.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:41.949610Z","iopub.execute_input":"2022-07-16T04:23:41.949930Z","iopub.status.idle":"2022-07-16T04:23:42.915471Z","shell.execute_reply.started":"2022-07-16T04:23:41.949896Z","shell.execute_reply":"2022-07-16T04:23:42.914438Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"loaded_model = keras.models.load_model('./feature_extractor.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:42.917254Z","iopub.execute_input":"2022-07-16T04:23:42.917700Z","iopub.status.idle":"2022-07-16T04:23:47.975030Z","shell.execute_reply.started":"2022-07-16T04:23:42.917666Z","shell.execute_reply":"2022-07-16T04:23:47.973758Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:47.977850Z","iopub.execute_input":"2022-07-16T04:23:47.978491Z","iopub.status.idle":"2022-07-16T04:23:49.377914Z","shell.execute_reply.started":"2022-07-16T04:23:47.978448Z","shell.execute_reply":"2022-07-16T04:23:49.376874Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model.output.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:49.379515Z","iopub.execute_input":"2022-07-16T04:23:49.380169Z","iopub.status.idle":"2022-07-16T04:23:49.387512Z","shell.execute_reply.started":"2022-07-16T04:23:49.380125Z","shell.execute_reply":"2022-07-16T04:23:49.386433Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"len(model.trainable_weights)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:49.388833Z","iopub.execute_input":"2022-07-16T04:23:49.389498Z","iopub.status.idle":"2022-07-16T04:23:49.406663Z","shell.execute_reply.started":"2022-07-16T04:23:49.389458Z","shell.execute_reply":"2022-07-16T04:23:49.405725Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### Feature Extraction by usinng pretrained models ","metadata":{}},{"cell_type":"code","source":"# for feature_extraction dataframe must have to contain file_name and  breed columns\ndef feature_extractor(df):\n    img_size = (331,331,3)\n    data_size = len(df)\n    batch_size = 20\n    X = np.zeros([data_size,3072], dtype=np.uint8)\n#     y = np.zeros([data_size,120], dtype=np.uint8)\n    datagen = ImageDataGenerator() # here we dont need to do any image augementaion because we are prediction features \n    generator = datagen.flow_from_dataframe(df,\n    x_col = 'file_name', class_mode = None, \n    batch_size=20, shuffle = False,target_size = (img_size[:2]),color_mode = 'rgb')\n    i = 0\n    \n    for input_batch in tqdm(generator):\n        input_batch = model.predict(input_batch)\n        X[i * batch_size : (i + 1) * batch_size] = input_batch\n        i += 1\n        if i * batch_size >= data_size:\n            break\n    return X\n ","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:49.409861Z","iopub.execute_input":"2022-07-16T04:23:49.410115Z","iopub.status.idle":"2022-07-16T04:23:49.418541Z","shell.execute_reply.started":"2022-07-16T04:23:49.410091Z","shell.execute_reply":"2022-07-16T04:23:49.417631Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"X = feature_extractor(labels_dataframe)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:23:49.420506Z","iopub.execute_input":"2022-07-16T04:23:49.421157Z","iopub.status.idle":"2022-07-16T04:27:31.408862Z","shell.execute_reply.started":"2022-07-16T04:23:49.421117Z","shell.execute_reply":"2022-07-16T04:27:31.407878Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:31.410181Z","iopub.execute_input":"2022-07-16T04:27:31.410758Z","iopub.status.idle":"2022-07-16T04:27:31.418744Z","shell.execute_reply.started":"2022-07-16T04:27:31.410716Z","shell.execute_reply":"2022-07-16T04:27:31.417477Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:31.426292Z","iopub.execute_input":"2022-07-16T04:27:31.427163Z","iopub.status.idle":"2022-07-16T04:27:31.434076Z","shell.execute_reply.started":"2022-07-16T04:27:31.427124Z","shell.execute_reply":"2022-07-16T04:27:31.433036Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"#### Defining some model callbacks for our training","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n#Prepare call backs\nEarlyStop_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('/kaggle/working/checkpoint',\n                             monitor = 'val_loss',mode = 'min',save_best_only= True)\nlr = ReduceLROnPlateau(monitor = 'val_loss',factor = 0.5,patience = 3,min_lr = 0.00001)\nmy_callback=[EarlyStop_callback,checkpoint]","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:31.435422Z","iopub.execute_input":"2022-07-16T04:27:31.436359Z","iopub.status.idle":"2022-07-16T04:27:31.445091Z","shell.execute_reply.started":"2022-07-16T04:27:31.436320Z","shell.execute_reply":"2022-07-16T04:27:31.444138Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"### Lets create a model for training \n","metadata":{}},{"cell_type":"code","source":"dnn = keras.models.Sequential([\n    InputLayer(X.shape[1:]),\n    Dropout(0.7),\n    Dense(n_classes, activation='softmax')\n])\n\ndnn.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#Train simple DNN on extracted features.\nh = dnn.fit(X , y,\n            batch_size=128,\n            epochs=60,\n            validation_split=0.1 ,\n           callbacks = my_callback)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:31.447667Z","iopub.execute_input":"2022-07-16T04:27:31.448228Z","iopub.status.idle":"2022-07-16T04:27:45.727095Z","shell.execute_reply.started":"2022-07-16T04:27:31.448184Z","shell.execute_reply":"2022-07-16T04:27:45.726196Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"#### Plot the result","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n\nax1.plot(h.history['loss'],color = 'b',label = 'loss')\nax1.plot(h.history['val_loss'],color = 'r',label = 'val_loss')\nax1.set_xticks(np.arange(1, 60, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\nax1.legend(['loss','val_loss'],shadow = True)\n\n\nax2.plot(h.history['accuracy'],color = 'green',label = 'accuracy')\nax2.plot(h.history['val_accuracy'],color = 'red',label = 'val_accuracy')\nax2.legend(['accuracy','val_accuracy'],shadow = True)\n# ax2.set_xticks(np.arange(1, 60, 1))\n# ax2.set_yticks(np.arange(0, 60, 0.1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:45.728503Z","iopub.execute_input":"2022-07-16T04:27:45.728859Z","iopub.status.idle":"2022-07-16T04:27:53.111374Z","shell.execute_reply.started":"2022-07-16T04:27:45.728832Z","shell.execute_reply":"2022-07-16T04:27:53.110340Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# saving the model\nfrom keras.models import load_model\ndnn.save('/kaggle/working/dogbreed.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:53.112863Z","iopub.execute_input":"2022-07-16T04:27:53.113429Z","iopub.status.idle":"2022-07-16T04:27:53.135307Z","shell.execute_reply.started":"2022-07-16T04:27:53.113374Z","shell.execute_reply":"2022-07-16T04:27:53.134447Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('dog_breeds_category.pickle', 'wb') as handle:\n    pickle.dump(dog_breeds, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:53.136752Z","iopub.execute_input":"2022-07-16T04:27:53.137103Z","iopub.status.idle":"2022-07-16T04:27:53.143471Z","shell.execute_reply.started":"2022-07-16T04:27:53.137067Z","shell.execute_reply":"2022-07-16T04:27:53.142166Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### its time for prediction \n","metadata":{}},{"cell_type":"code","source":"test_data = []\nids = []\nfor pic in os.listdir(test_dir):\n    ids.append(pic.split('.')[0])\n    test_data.append(test_dir+pic)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:53.145190Z","iopub.execute_input":"2022-07-16T04:27:53.145552Z","iopub.status.idle":"2022-07-16T04:27:53.165185Z","shell.execute_reply.started":"2022-07-16T04:27:53.145516Z","shell.execute_reply":"2022-07-16T04:27:53.164389Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test_dataframe = pd.DataFrame({'file_name':test_data})\n# we are converting into a dataframe beacause our feature extractor funtion only support dataframe","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:53.166354Z","iopub.execute_input":"2022-07-16T04:27:53.166780Z","iopub.status.idle":"2022-07-16T04:27:53.173320Z","shell.execute_reply.started":"2022-07-16T04:27:53.166743Z","shell.execute_reply":"2022-07-16T04:27:53.172198Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"test_features = feature_extractor(test_dataframe)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:27:53.175019Z","iopub.execute_input":"2022-07-16T04:27:53.175713Z","iopub.status.idle":"2022-07-16T04:31:19.311864Z","shell.execute_reply.started":"2022-07-16T04:27:53.175678Z","shell.execute_reply":"2022-07-16T04:31:19.310286Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"y_pred = dnn.predict(test_features)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:19.313448Z","iopub.execute_input":"2022-07-16T04:31:19.313736Z","iopub.status.idle":"2022-07-16T04:31:19.638258Z","shell.execute_reply.started":"2022-07-16T04:31:19.313709Z","shell.execute_reply":"2022-07-16T04:31:19.637269Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def get_key(val): \n    for key, value in class_to_num.items(): \n        if val == value: \n            return key \npred_codes = np.argmax(y_pred, axis = 1)\npredictions = []\nfor i in pred_codes:\n    predictions.append(get_key(i))","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:19.639583Z","iopub.execute_input":"2022-07-16T04:31:19.640960Z","iopub.status.idle":"2022-07-16T04:31:19.829738Z","shell.execute_reply.started":"2022-07-16T04:31:19.640919Z","shell.execute_reply":"2022-07-16T04:31:19.828620Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test_dataframe['breed'] = predictions","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:19.831567Z","iopub.execute_input":"2022-07-16T04:31:19.831938Z","iopub.status.idle":"2022-07-16T04:31:19.838014Z","shell.execute_reply.started":"2022-07-16T04:31:19.831902Z","shell.execute_reply":"2022-07-16T04:31:19.836966Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(suppress=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:19.839903Z","iopub.execute_input":"2022-07-16T04:31:19.840725Z","iopub.status.idle":"2022-07-16T04:31:19.847211Z","shell.execute_reply.started":"2022-07-16T04:31:19.840686Z","shell.execute_reply":"2022-07-16T04:31:19.846277Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.float_format', lambda x: '%.10f' % x)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:19.848620Z","iopub.execute_input":"2022-07-16T04:31:19.849015Z","iopub.status.idle":"2022-07-16T04:31:19.858102Z","shell.execute_reply.started":"2022-07-16T04:31:19.848979Z","shell.execute_reply":"2022-07-16T04:31:19.857225Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"#### creating submission  file for the competetion","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame(y_pred, columns = dog_breeds)\nsubmission['id'] = ids\n","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:19.860589Z","iopub.execute_input":"2022-07-16T04:31:19.860920Z","iopub.status.idle":"2022-07-16T04:31:19.869884Z","shell.execute_reply.started":"2022-07-16T04:31:19.860891Z","shell.execute_reply":"2022-07-16T04:31:19.868648Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"submission.set_index('id')","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:19.873084Z","iopub.execute_input":"2022-07-16T04:31:19.873337Z","iopub.status.idle":"2022-07-16T04:31:19.906258Z","shell.execute_reply.started":"2022-07-16T04:31:19.873314Z","shell.execute_reply":"2022-07-16T04:31:19.905265Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('sumbmission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:19.909246Z","iopub.execute_input":"2022-07-16T04:31:19.909533Z","iopub.status.idle":"2022-07-16T04:31:21.664453Z","shell.execute_reply.started":"2022-07-16T04:31:19.909507Z","shell.execute_reply":"2022-07-16T04:31:21.663224Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"### Plotting some images ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(6,6))\n\nfor index , data in test_dataframe[:10].iterrows():\n    img = data['file_name']\n    label = data['breed']\n    img = cv2.imread(img)\n#     plt.subplot(2,5, index+1)\n    plt.imshow(img)\n    plt.xlabel(label,fontsize = (15))\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-16T04:31:21.669311Z","iopub.execute_input":"2022-07-16T04:31:21.669880Z","iopub.status.idle":"2022-07-16T04:31:24.650223Z","shell.execute_reply.started":"2022-07-16T04:31:21.669838Z","shell.execute_reply":"2022-07-16T04:31:24.649337Z"},"trusted":true},"execution_count":45,"outputs":[]}]}